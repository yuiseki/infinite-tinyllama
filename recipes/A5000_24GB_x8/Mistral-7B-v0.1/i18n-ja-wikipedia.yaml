target_task: tasks/i18n/ja.md
base_model_id: mistralai/Mistral-7B-v0.1
model_name: Mistral-7B-v0.1-ja-wikipedia-v0.1
output_base_dir: output
dataset_id: wikimedia/wikipedia
dataset_load_config: 20231101.ja
dataset_input_field_name: text
dataset_train_split_seed: 42
dataset_train_split_test_size: 0.2
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
train_claim_gpu_num: 8
train_per_device_train_batch_size: 1
train_gradient_accumulation_steps: 16
train_num_train_epochs: 2
